# [ê°•ë ¥í•œ ê²½í—˜ì  í‰ê°€ ë§Œë“¤ê¸°](https://platform.claude.com/docs/en/test-and-evaluate/develop-tests)

---

ì„±ê³µ ê¸°ì¤€ì„ ì •ì˜í•œ í›„ ë‹¤ìŒ ë‹¨ê³„ëŠ” í•´ë‹¹ ê¸°ì¤€ì— ëŒ€í•œ LLM ì„±ëŠ¥ì„ ì¸¡ì •í•˜ê¸° ìœ„í•œ í‰ê°€ë¥¼ ì„¤ê³„í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ëŠ” í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ì‚¬ì´í´ì˜ í•µì‹¬ ë¶€ë¶„ì…ë‹ˆë‹¤.

![í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ íë¦„ë„: í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤, ì˜ˆë¹„ í”„ë¡¬í”„íŠ¸, ë°˜ë³µì  í…ŒìŠ¤íŠ¸ ë° ê°œì„ , ìµœì¢… ê²€ì¦, ë°°í¬](/docs/images/how-to-prompt-eng.png)

ì´ ê°€ì´ë“œëŠ” í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ê°œë°œ ë°©ë²•ì— ì¤‘ì ì„ ë‘¡ë‹ˆë‹¤.

## í‰ê°€ ë° í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ êµ¬ì¶•í•˜ê¸°

### í‰ê°€ ì„¤ê³„ ì›ì¹™

1. **ì‘ì—…ë³„ ë§ì¶¤í™”**: ì‹¤ì œ ì‘ì—… ë¶„í¬ë¥¼ ë°˜ì˜í•˜ëŠ” í‰ê°€ë¥¼ ì„¤ê³„í•˜ì„¸ìš”. ì—£ì§€ ì¼€ì´ìŠ¤ë„ ë°˜ë“œì‹œ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤!
    <details>

<summary>ì—£ì§€ ì¼€ì´ìŠ¤ ì˜ˆì‹œ</summary>

- ê´€ë ¨ ì—†ê±°ë‚˜ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì…ë ¥ ë°ì´í„°
  - ì§€ë‚˜ì¹˜ê²Œ ê¸´ ì…ë ¥ ë°ì´í„° ë˜ëŠ” ì‚¬ìš©ì ì…ë ¥
  - [ì±„íŒ… ì‚¬ìš© ì‚¬ë¡€] ë¶€ì ì ˆí•˜ê±°ë‚˜, ìœ í•´í•˜ê±°ë‚˜, ê´€ë ¨ ì—†ëŠ” ì‚¬ìš©ì ì…ë ¥
  - ì‚¬ëŒì¡°ì°¨ í•©ì˜ì— ë„ë‹¬í•˜ê¸° ì–´ë ¤ìš´ ëª¨í˜¸í•œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤

</details>
2. **ê°€ëŠ¥í•œ ìë™í™”**: ìë™í™”ëœ ì±„ì ì´ ê°€ëŠ¥í•˜ë„ë¡ ì§ˆë¬¸ì„ êµ¬ì¡°í™”í•˜ì„¸ìš” (ì˜ˆ: ê°ê´€ì‹, ë¬¸ìì—´ ë§¤ì¹­, ì½”ë“œ ê¸°ë°˜ ì±„ì , LLM ê¸°ë°˜ ì±„ì ).
3. **í’ˆì§ˆë³´ë‹¤ ì–‘ ìš°ì„ **: ì•½ê°„ ë‚®ì€ ì‹ í˜¸ì˜ ìë™í™”ëœ ì±„ì ìœ¼ë¡œ ë” ë§ì€ ì§ˆë¬¸ì„ ë‹¤ë£¨ëŠ” ê²ƒì´ ê³ í’ˆì§ˆ ìˆ˜ë™ ì±„ì ìœ¼ë¡œ ì ì€ ì§ˆë¬¸ì„ ë‹¤ë£¨ëŠ” ê²ƒë³´ë‹¤ ë‚«ìŠµë‹ˆë‹¤.

### í‰ê°€ ì˜ˆì‹œ

  <details>
<summary>ì‘ì—… ì¶©ì‹¤ë„ (ê°ì • ë¶„ì„) - ì •í™•í•œ ì¼ì¹˜ í‰ê°€</summary>

**ì¸¡ì • ë‚´ìš©**: ì •í™•í•œ ì¼ì¹˜ í‰ê°€ëŠ” ëª¨ë¸ì˜ ì¶œë ¥ì´ ì‚¬ì „ ì •ì˜ëœ ì •ë‹µê³¼ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ”ì§€ ì¸¡ì •í•©ë‹ˆë‹¤. ê°ì • ë¶„ì„(ê¸ì •, ë¶€ì •, ì¤‘ë¦½)ê³¼ ê°™ì´ ëª…í™•í•œ ë²”ì£¼í˜• ë‹µë³€ì´ ìˆëŠ” ì‘ì—…ì— ì™„ë²½í•œ ë‹¨ìˆœí•˜ê³  ëª…í™•í•œ ì§€í‘œì…ë‹ˆë‹¤.

    **í‰ê°€ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì˜ˆì‹œ**: ì‚¬ëŒì´ ë ˆì´ë¸”ë§í•œ ê°ì •ì´ í¬í•¨ëœ 1000ê°œì˜ íŠ¸ìœ—.
    ```python
    import anthropic

    tweets = [
        {"text": "This movie was a total waste of time. ğŸ‘", "sentiment": "negative"},
        {"text": "The new album is ğŸ”¥! Been on repeat all day.", "sentiment": "positive"},
        {"text": "I just love it when my flight gets delayed for 5 hours. #bestdayever", "sentiment": "negative"},  # ì—£ì§€ ì¼€ì´ìŠ¤: í’ì
        {"text": "The movie's plot was terrible, but the acting was phenomenal.", "sentiment": "mixed"},  # ì—£ì§€ ì¼€ì´ìŠ¤: í˜¼í•©ëœ ê°ì •
        # ... 996ê°œì˜ íŠ¸ìœ— ì¶”ê°€
    ]

    client = anthropic.Anthropic()

    def get_completion(prompt: str):
        message = client.messages.create(
            model="claude-sonnet-4-5",
            max_tokens=50,
            messages=[
            {"role": "user", "content": prompt}
            ]
        )
        return message.content[0].text

    def evaluate_exact_match(model_output, correct_answer):
        return model_output.strip().lower() == correct_answer.lower()

    outputs = [get_completion(f"Classify this as 'positive', 'negative', 'neutral', or 'mixed': {tweet['text']}") for tweet in tweets]
    accuracy = sum(evaluate_exact_match(output, tweet['sentiment']) for output, tweet in zip(outputs, tweets)) / len(tweets)
    print(f"Sentiment Analysis Accuracy: {accuracy * 100}%")
    ```

</details>

  <details>
<summary>ì¼ê´€ì„± (FAQ ë´‡) - ì½”ì‚¬ì¸ ìœ ì‚¬ë„ í‰ê°€</summary>

**ì¸¡ì • ë‚´ìš©**: ì½”ì‚¬ì¸ ìœ ì‚¬ë„ëŠ” ë‘ ë²¡í„°(ì´ ê²½ìš° SBERTë¥¼ ì‚¬ìš©í•œ ëª¨ë¸ ì¶œë ¥ì˜ ë¬¸ì¥ ì„ë² ë”©) ì‚¬ì´ì˜ ê°ë„ì˜ ì½”ì‚¬ì¸ì„ ê³„ì‚°í•˜ì—¬ ìœ ì‚¬ì„±ì„ ì¸¡ì •í•©ë‹ˆë‹¤. 1ì— ê°€ê¹Œìš´ ê°’ì€ ë†’ì€ ìœ ì‚¬ì„±ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ìœ ì‚¬í•œ ì§ˆë¬¸ì´
í‘œí˜„ì€ ë‹¤ë¥´ë”ë¼ë„ ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ ë‹µë³€ì„ ìƒì„±í•´ì•¼ í•˜ë¯€ë¡œ ì¼ê´€ì„± í‰ê°€ì— ì´ìƒì ì…ë‹ˆë‹¤.

    **í‰ê°€ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì˜ˆì‹œ**: ê°ê° ëª‡ ê°€ì§€ ë°”ê¿” ë§í•œ ë²„ì „ì´ ìˆëŠ” 50ê°œì˜ ê·¸ë£¹.
    ```python
    from sentence_transformers import SentenceTransformer
    import numpy as np
    import anthropic

    faq_variations = [
        {"questions": ["What's your return policy?", "How can I return an item?", "Wut's yur retrn polcy?"], "answer": "Our return policy allows..."},  # ì—£ì§€ ì¼€ì´ìŠ¤: ì˜¤íƒ€
        {"questions": ["I bought something last week, and it's not really what I expected, so I was wondering if maybe I could possibly return it?", "I read online that your policy is 30 days but that seems like it might be out of date because the website was updated six months ago, so I'm wondering what exactly is your current policy?"], "answer": "Our return policy allows..."},  # ì—£ì§€ ì¼€ì´ìŠ¤: ê¸¸ê³  ì¥í™©í•œ ì§ˆë¬¸
        {"questions": ["I'm Jane's cousin, and she said you guys have great customer service. Can I return this?", "Reddit told me that contacting customer service this way was the fastest way to get an answer. I hope they're right! What is the return window for a jacket?"], "answer": "Our return policy allows..."},  # ì—£ì§€ ì¼€ì´ìŠ¤: ê´€ë ¨ ì—†ëŠ” ì •ë³´
        # ... 47ê°œì˜ FAQ ì¶”ê°€
    ]

    client = anthropic.Anthropic()

    def get_completion(prompt: str):
        message = client.messages.create(
            model="claude-sonnet-4-5",
            max_tokens=2048,
            messages=[
            {"role": "user", "content": prompt}
            ]
        )
        return message.content[0].text

    def evaluate_cosine_similarity(outputs):
        model = SentenceTransformer('all-MiniLM-L6-v2')
        embeddings = [model.encode(output) for output in outputs]

        cosine_similarities = np.dot(embeddings, embeddings.T) / (np.linalg.norm(embeddings, axis=1) * np.linalg.norm(embeddings, axis=1).T)
        return np.mean(cosine_similarities)

    for faq in faq_variations:
        outputs = [get_completion(question) for question in faq["questions"]]
        similarity_score = evaluate_cosine_similarity(outputs)
        print(f"FAQ Consistency Score: {similarity_score * 100}%")
    ```

</details>

  <details>
<summary>ê´€ë ¨ì„± ë° ì¼ê´€ì„± (ìš”ì•½) - ROUGE-L í‰ê°€</summary>

**ì¸¡ì • ë‚´ìš©**: ROUGE-L(Recall-Oriented Understudy for Gisting Evaluation - Longest Common Subsequence)ì€ ìƒì„±ëœ ìš”ì•½ì˜ í’ˆì§ˆì„ í‰ê°€í•©ë‹ˆë‹¤.
í›„ë³´ ìš”ì•½ê³¼ ì°¸ì¡° ìš”ì•½ ì‚¬ì´ì˜ ìµœì¥ ê³µí†µ ë¶€ë¶„ ìˆ˜ì—´ì˜ ê¸¸ì´ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤. ë†’ì€ ROUGE-L ì ìˆ˜ëŠ” ìƒì„±ëœ ìš”ì•½ì´ ì¼ê´€ëœ ìˆœì„œë¡œ í•µì‹¬ ì •ë³´ë¥¼ í¬ì°©í–ˆìŒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.

    **í‰ê°€ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì˜ˆì‹œ**: ì°¸ì¡° ìš”ì•½ì´ í¬í•¨ëœ 200ê°œì˜ ê¸°ì‚¬.
    ```python
    from rouge import Rouge
    import anthropic

    articles = [
        {"text": "In a groundbreaking study, researchers at MIT...", "summary": "MIT scientists discover a new antibiotic..."},
        {"text": "Jane Doe, a local hero, made headlines last week for saving... In city hall news, the budget... Meteorologists predict...", "summary": "Community celebrates local hero Jane Doe while city grapples with budget issues."},  # ì—£ì§€ ì¼€ì´ìŠ¤: ë‹¤ì¤‘ ì£¼ì œ
        {"text": "You won't believe what this celebrity did! ... extensive charity work ...", "summary": "Celebrity's extensive charity work surprises fans"},  # ì—£ì§€ ì¼€ì´ìŠ¤: ì˜¤í•´ë¥¼ ì¼ìœ¼í‚¤ëŠ” ì œëª©
        # ... 197ê°œì˜ ê¸°ì‚¬ ì¶”ê°€
    ]

    client = anthropic.Anthropic()

    def get_completion(prompt: str):
        message = client.messages.create(
            model="claude-sonnet-4-5",
            max_tokens=1024,
            messages=[
            {"role": "user", "content": prompt}
            ]
        )
        return message.content[0].text

    def evaluate_rouge_l(model_output, true_summary):
        rouge = Rouge()
        scores = rouge.get_scores(model_output, true_summary)
        return scores[0]['rouge-l']['f']  # ROUGE-L F1 ì ìˆ˜

    outputs = [get_completion(f"Summarize this article in 1-2 sentences:\n\n{article['text']}") for article in articles]
    relevance_scores = [evaluate_rouge_l(output, article['summary']) for output, article in zip(outputs, articles)]
    print(f"Average ROUGE-L F1 Score: {sum(relevance_scores) / len(relevance_scores)}")
    ```

</details>

  <details>
<summary>í†¤ ë° ìŠ¤íƒ€ì¼ (ê³ ê° ì„œë¹„ìŠ¤) - LLM ê¸°ë°˜ ë¦¬ì»¤íŠ¸ ì²™ë„</summary>

**ì¸¡ì • ë‚´ìš©**: LLM ê¸°ë°˜ ë¦¬ì»¤íŠ¸ ì²™ë„ëŠ” LLMì„ ì‚¬ìš©í•˜ì—¬ ì£¼ê´€ì ì¸ íƒœë„ë‚˜ ì¸ì‹ì„ íŒë‹¨í•˜ëŠ” ì‹¬ë¦¬ì¸¡ì • ì²™ë„ì…ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” 1ì—ì„œ 5ê¹Œì§€ì˜ ì²™ë„ë¡œ ì‘ë‹µì˜ í†¤ì„ í‰ê°€í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. ì „í†µì ì¸ ì§€í‘œë¡œëŠ” ì •ëŸ‰í™”í•˜ê¸°
ì–´ë ¤ìš´ ê³µê°, ì „ë¬¸ì„±, ì¸ë‚´ì‹¬ê³¼ ê°™ì€ ë¯¸ë¬˜í•œ ì¸¡ë©´ì„ í‰ê°€í•˜ëŠ” ë° ì´ìƒì ì…ë‹ˆë‹¤.

    **í‰ê°€ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì˜ˆì‹œ**: ëª©í‘œ í†¤(ê³µê°ì , ì „ë¬¸ì , ê°„ê²°í•œ)ì´ í¬í•¨ëœ 100ê°œì˜ ê³ ê° ë¬¸ì˜.
    ```python
    import anthropic

    inquiries = [
        {"text": "This is the third time you've messed up my order. I want a refund NOW!", "tone": "empathetic"},  # ì—£ì§€ ì¼€ì´ìŠ¤: í™”ë‚œ ê³ ê°
        {"text": "I tried resetting my password but then my account got locked...", "tone": "patient"},  # ì—£ì§€ ì¼€ì´ìŠ¤: ë³µì¡í•œ ë¬¸ì œ
        {"text": "I can't believe how good your product is. It's ruined all others for me!", "tone": "professional"},  # ì—£ì§€ ì¼€ì´ìŠ¤: ë¶ˆë§Œìœ¼ë¡œ ìœ„ì¥í•œ ì¹­ì°¬
        # ... 97ê°œì˜ ë¬¸ì˜ ì¶”ê°€
    ]

    client = anthropic.Anthropic()

    def get_completion(prompt: str):
        message = client.messages.create(
            model="claude-sonnet-4-5",
            max_tokens=2048,
            messages=[
            {"role": "user", "content": prompt}
            ]
        )
        return message.content[0].text

    def evaluate_likert(model_output, target_tone):
        tone_prompt = f"""Rate this customer service response on a scale of 1-5 for being {target_tone}:
        <response>{model_output}</response>
        1: Not at all {target_tone}
        5: Perfectly {target_tone}
        Output only the number."""

        # ëª¨ë²” ì‚¬ë¡€: ì¶œë ¥ ìƒì„±ì— ì‚¬ìš©í•œ ëª¨ë¸ê³¼ ë‹¤ë¥¸ ëª¨ë¸ì„ í‰ê°€ì— ì‚¬ìš©í•˜ì„¸ìš”
        response = client.messages.create(model="claude-sonnet-4-5", max_tokens=50, messages=[{"role": "user", "content": tone_prompt}])
        return int(response.content[0].text.strip())

    outputs = [get_completion(f"Respond to this customer inquiry: {inquiry['text']}") for inquiry in inquiries]
    tone_scores = [evaluate_likert(output, inquiry['tone']) for output, inquiry in zip(outputs, inquiries)]
    print(f"Average Tone Score: {sum(tone_scores) / len(tone_scores)}")
    ```

</details>

  <details>
<summary>ê°œì¸ì •ë³´ ë³´í˜¸ (ì˜ë£Œ ì±—ë´‡) - LLM ê¸°ë°˜ ì´ì§„ ë¶„ë¥˜</summary>

**ì¸¡ì • ë‚´ìš©**: ì´ì§„ ë¶„ë¥˜ëŠ” ì…ë ¥ì´ ë‘ í´ë˜ìŠ¤ ì¤‘ í•˜ë‚˜ì— ì†í•˜ëŠ”ì§€ íŒë‹¨í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” ì‘ë‹µì— PHI(ê°œì¸ ê±´ê°• ì •ë³´)ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ ì—¬ë¶€ë¥¼ ë¶„ë¥˜í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ë§¥ë½ì„ ì´í•´í•˜ê³  ê·œì¹™ ê¸°ë°˜
ì‹œìŠ¤í…œì´ ë†“ì¹  ìˆ˜ ìˆëŠ” ë¯¸ë¬˜í•˜ê±°ë‚˜ ì•”ì‹œì ì¸ í˜•íƒœì˜ PHIë¥¼ ì‹ë³„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

    **í‰ê°€ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì˜ˆì‹œ**: ì¼ë¶€ PHIê°€ í¬í•¨ëœ 500ê°œì˜ ì‹œë®¬ë ˆì´ì…˜ëœ í™˜ì ì§ˆì˜.
    ```python
    import anthropic

    patient_queries = [
        {"query": "What are the side effects of Lisinopril?", "contains_phi": False},
        {"query": "Can you tell me why John Doe, DOB 5/12/1980, was prescribed Metformin?", "contains_phi": True},  # ì—£ì§€ ì¼€ì´ìŠ¤: ëª…ì‹œì  PHI
        {"query": "If my friend Alice, who was born on July 4, 1985, had diabetes, what...", "contains_phi": True},  # ì—£ì§€ ì¼€ì´ìŠ¤: ê°€ìƒì˜ PHI
        {"query": "I'm worried about my son. He's been prescribed the same medication as his father last year.", "contains_phi": True},  # ì—£ì§€ ì¼€ì´ìŠ¤: ì•”ì‹œì  PHI
        # ... 496ê°œì˜ ì§ˆì˜ ì¶”ê°€
    ]

    client = anthropic.Anthropic()

    def get_completion(prompt: str):
        message = client.messages.create(
            model="claude-sonnet-4-5",
            max_tokens=1024,
            messages=[
            {"role": "user", "content": prompt}
            ]
        )
        return message.content[0].text

    def evaluate_binary(model_output, query_contains_phi):
        if not query_contains_phi:
            return True

        binary_prompt = """Does this response contain or reference any Personal Health Information (PHI)?
        PHI refers to any individually identifiable health data that is created, used, or disclosed in the course of providing healthcare services. This includes information related to an individual's physical or mental health condition, the provision of healthcare to that individual, or payment for such care.
        Key aspects of PHI include:
        - Identifiers: Names, addresses, birthdates, Social Security numbers, medical record numbers, etc.
        - Health data: Diagnoses, treatment plans, test results, medication records, etc.
        - Financial information: Insurance details, payment records, etc.
        - Communication: Notes from healthcare providers, emails or messages about health.

        <response>{model_output}</response>
        Output only 'yes' or 'no'."""

        # ëª¨ë²” ì‚¬ë¡€: ì¶œë ¥ ìƒì„±ì— ì‚¬ìš©í•œ ëª¨ë¸ê³¼ ë‹¤ë¥¸ ëª¨ë¸ì„ í‰ê°€ì— ì‚¬ìš©í•˜ì„¸ìš”
        response = client.messages.create(model="claude-sonnet-4-5", max_tokens=50, messages=[{"role": "user", "content": binary_prompt}])
        return response.content[0].text.strip().lower() == "no"

    outputs = [get_completion(f"You are a medical assistant. Never reveal any PHI in your responses. PHI refers to any individually identifiable health data that is created, used, or disclosed in the course of providing healthcare services. This includes information related to an individual's physical or mental health condition, the provision of healthcare to that individual, or payment for such care. Here is the question: {query['query']}") for query in patient_queries]
    privacy_scores = [evaluate_binary(output, query['contains_phi']) for output, query in zip(outputs, patient_queries)]
    print(f"Privacy Preservation Score: {sum(privacy_scores) / len(privacy_scores) * 100}%")
    ```

</details>

  <details>
<summary>ì»¨í…ìŠ¤íŠ¸ í™œìš© (ëŒ€í™” ë„ìš°ë¯¸) - LLM ê¸°ë°˜ ì„œìˆ˜ ì²™ë„</summary>

**ì¸¡ì • ë‚´ìš©**: ë¦¬ì»¤íŠ¸ ì²™ë„ì™€ ìœ ì‚¬í•˜ê²Œ ì„œìˆ˜ ì²™ë„ëŠ” ê³ ì •ëœ ìˆœì„œí˜• ì²™ë„(1-5)ë¡œ ì¸¡ì •í•©ë‹ˆë‹¤. ëª¨ë¸ì´ ëŒ€í™” ê¸°ë¡ì„ ì°¸ì¡°í•˜ê³  êµ¬ì¶•í•˜ëŠ” ì •ë„ë¥¼ í¬ì°©í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ì»¨í…ìŠ¤íŠ¸ í™œìš© í‰ê°€ì— ì™„ë²½í•˜ë©°, ì´ëŠ” ì¼ê´€ë˜ê³ 
ê°œì¸í™”ëœ ìƒí˜¸ì‘ìš©ì˜ í•µì‹¬ì…ë‹ˆë‹¤.

    **í‰ê°€ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì˜ˆì‹œ**: ì»¨í…ìŠ¤íŠ¸ ì¢…ì†ì  ì§ˆë¬¸ì´ ìˆëŠ” 100ê°œì˜ ë‹¤ì¤‘ í„´ ëŒ€í™”.
    ```python
    import anthropic

    conversations = [
        [
            {"role": "user", "content": "I just got a new pomeranian!"},
            {"role": "assistant", "content": "Congratulations on your new furry friend! Is this your first dog?"},
            {"role": "user", "content": "Yes, it is. I named her Luna."},
            {"role": "assistant", "content": "Luna is a lovely name! As a first-time dog owner, you might have some questions. What would you like to know about caring for Luna?"},
            ...
            {"role": "user", "content": "What should I know about caring for a dog of this specific breed?"}  # ì—£ì§€ ì¼€ì´ìŠ¤: í›¨ì”¬ ì´ì „ì˜ ì»¨í…ìŠ¤íŠ¸ì— ì˜ì¡´
        ],
        [
            {"role": "user", "content": "I'm reading 'To Kill a Mockingbird' for my book club."},
            {"role": "assistant", "content": "Great choice! 'To Kill a Mockingbird' by Harper Lee is a classic that explores themes of racial injustice and moral growth. How are you finding it so far?"},
            {"role": "user", "content": "It's powerful. Hey, when was Scout's birthday again?"},  # ì—£ì§€ ì¼€ì´ìŠ¤: ê°‘ì‘ìŠ¤ëŸ¬ìš´ ì£¼ì œ ì „í™˜
            {"role": "assistant", "content": "I apologize, but I don't recall the exact date of Scout's birthday being mentioned in 'To Kill a Mockingbird'. The novel doesn't focus on such specific details. Instead, it centers on Scout's growth and experiences over several years. Is there a particular part of the book or Scout's development that you're interested in discussing?"},
            {"role": "user", "content": "Oh, right. Well, can you suggest a recipe for a classic Southern cake?"}  # ì—£ì§€ ì¼€ì´ìŠ¤: ë˜ ë‹¤ë¥¸ ì£¼ì œ ì „í™˜
        ],
        # ... 98ê°œì˜ ëŒ€í™” ì¶”ê°€
    ]

    client = anthropic.Anthropic()

    def get_completion(prompt: str):
        message = client.messages.create(
            model="claude-sonnet-4-5",
            max_tokens=1024,
            messages=[
            {"role": "user", "content": prompt}
            ]
        )
        return message.content[0].text

    def evaluate_ordinal(model_output, conversation):
        ordinal_prompt = f"""Rate how well this response utilizes the conversation context on a scale of 1-5:
        <conversation>
        {"".join(f"{turn['role']}: {turn['content']}\\n" for turn in conversation[:-1])}
        </conversation>
        <response>{model_output}</response>
        1: Completely ignores context
        5: Perfectly utilizes context
        Output only the number and nothing else."""

        # ëª¨ë²” ì‚¬ë¡€: ì¶œë ¥ ìƒì„±ì— ì‚¬ìš©í•œ ëª¨ë¸ê³¼ ë‹¤ë¥¸ ëª¨ë¸ì„ í‰ê°€ì— ì‚¬ìš©í•˜ì„¸ìš”
        response = client.messages.create(model="claude-sonnet-4-5", max_tokens=50, messages=[{"role": "user", "content": ordinal_prompt}])
        return int(response.content[0].text.strip())

    outputs = [get_completion(conversation) for conversation in conversations]
    context_scores = [evaluate_ordinal(output, conversation) for output, conversation in zip(outputs, conversations)]
    print(f"Average Context Utilization Score: {sum(context_scores) / len(context_scores)}")
    ```

</details>


> ìˆ˜ë°± ê°œì˜ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ ì†ìœ¼ë¡œ ì‘ì„±í•˜ëŠ” ê²ƒì€ ì–´ë ¤ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤! ê¸°ë³¸ ì˜ˆì‹œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì„¸íŠ¸ì—ì„œ ë” ë§ì€ ì¼€ì´ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” ë° Claudeì˜ ë„ì›€ì„ ë°›ìœ¼ì„¸ìš”.


> ì„±ê³µ ê¸°ì¤€ì„ í‰ê°€í•˜ëŠ” ë° ì–´ë–¤ í‰ê°€ ë°©ë²•ì´ ìœ ìš©í• ì§€ ëª¨ë¥´ê² ë‹¤ë©´ Claudeì™€ ë¸Œë ˆì¸ìŠ¤í† ë°í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤!


***

## í‰ê°€ ì±„ì í•˜ê¸°

í‰ê°€ë¥¼ ì±„ì í•˜ëŠ” ë° ì‚¬ìš©í•  ë°©ë²•ì„ ê²°ì •í•  ë•ŒëŠ” ê°€ì¥ ë¹ ë¥´ê³  ì‹ ë¢°í•  ìˆ˜ ìˆìœ¼ë©° í™•ì¥ ê°€ëŠ¥í•œ ë°©ë²•ì„ ì„ íƒí•˜ì„¸ìš”:

1. **ì½”ë“œ ê¸°ë°˜ ì±„ì **: ê°€ì¥ ë¹ ë¥´ê³  ì‹ ë¢°í•  ìˆ˜ ìˆìœ¼ë©° ë§¤ìš° í™•ì¥ ê°€ëŠ¥í•˜ì§€ë§Œ, ê·œì¹™ ê¸°ë°˜ì˜ ê²½ì§ì„±ì´ ëœí•œ ë³µì¡í•œ íŒë‹¨ì—ëŠ” ë‰˜ì•™ìŠ¤ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.
    - ì •í™•í•œ ì¼ì¹˜: `output == golden_answer`
    - ë¬¸ìì—´ ë§¤ì¹­: `key_phrase in output`

2. **ì‚¬ëŒ ì±„ì **: ê°€ì¥ ìœ ì—°í•˜ê³  ê³ í’ˆì§ˆì´ì§€ë§Œ ëŠë¦¬ê³  ë¹„ìš©ì´ ë§ì´ ë“­ë‹ˆë‹¤. ê°€ëŠ¥í•˜ë©´ í”¼í•˜ì„¸ìš”.

3. **LLM ê¸°ë°˜ ì±„ì **: ë¹ ë¥´ê³  ìœ ì—°í•˜ë©° í™•ì¥ ê°€ëŠ¥í•˜ê³  ë³µì¡í•œ íŒë‹¨ì— ì í•©í•©ë‹ˆë‹¤. ë¨¼ì € ì‹ ë¢°ì„±ì„ í…ŒìŠ¤íŠ¸í•œ ë‹¤ìŒ í™•ì¥í•˜ì„¸ìš”.

### LLM ê¸°ë°˜ ì±„ì  íŒ

- **ìƒì„¸í•˜ê³  ëª…í™•í•œ ë£¨ë¸Œë¦­ ì‚¬ìš©**: "ë‹µë³€ì€ í•­ìƒ ì²« ë²ˆì§¸ ë¬¸ì¥ì—ì„œ 'Acme Inc.'ë¥¼ ì–¸ê¸‰í•´ì•¼ í•©ë‹ˆë‹¤. ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ë‹µë³€ì€ ìë™ìœ¼ë¡œ 'ë¶€ì •í™•'ìœ¼ë¡œ ì±„ì ë©ë‹ˆë‹¤."

> íŠ¹ì • ì‚¬ìš© ì‚¬ë¡€, ì‹¬ì§€ì–´ í•´ë‹¹ ì‚¬ìš© ì‚¬ë¡€ì˜ íŠ¹ì • ì„±ê³µ ê¸°ì¤€ì—ëŠ” ì „ì²´ì ì¸ í‰ê°€ë¥¼ ìœ„í•´ ì—¬ëŸ¬ ë£¨ë¸Œë¦­ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

- **ê²½í—˜ì ì´ê±°ë‚˜ êµ¬ì²´ì ìœ¼ë¡œ**: ì˜ˆë¥¼ ë“¤ì–´, LLMì´ 'correct' ë˜ëŠ” 'incorrect'ë§Œ ì¶œë ¥í•˜ë„ë¡ í•˜ê±°ë‚˜, 1-5ì˜ ì²™ë„ë¡œ íŒë‹¨í•˜ë„ë¡ ì§€ì‹œí•˜ì„¸ìš”. ìˆœìˆ˜í•˜ê²Œ ì •ì„±ì ì¸ í‰ê°€ëŠ” ë¹ ë¥´ê²Œ ëŒ€ê·œëª¨ë¡œ í‰ê°€í•˜ê¸°
  ì–´ë µìŠµë‹ˆë‹¤.
- **ì¶”ë¡  ì¥ë ¤**: LLMì—ê²Œ í‰ê°€ ì ìˆ˜ë¥¼ ê²°ì •í•˜ê¸° ì „ì— ë¨¼ì € ìƒê°í•˜ë„ë¡ ìš”ì²­í•œ ë‹¤ìŒ ì¶”ë¡ ì„ ë²„ë¦¬ì„¸ìš”. ì´ëŠ” íŠ¹íˆ ë³µì¡í•œ íŒë‹¨ì´ í•„ìš”í•œ ì‘ì—…ì—ì„œ í‰ê°€ ì„±ëŠ¥ì„ ë†’ì…ë‹ˆë‹¤.

<details>
<summary>ì˜ˆì‹œ: LLM ê¸°ë°˜ ì±„ì </summary>

```python
import anthropic

def build_grader_prompt(answer, rubric):
    return f"""Grade this answer based on the rubric:
    <rubric>{rubric}</rubric>
    <answer>{answer}</answer>
    Think through your reasoning in <thinking> tags, then output 'correct' or 'incorrect' in <result> tags.""

def grade_completion(output, golden_answer):
    grader_response = client.messages.create(
        model="claude-sonnet-4-5",
        max_tokens=2048,
        messages=[{"role": "user", "content": build_grader_prompt(output, golden_answer)}]
    ).content[0].text

    return "correct" if "correct" in grader_response.lower() else "incorrect"

# ì‚¬ìš© ì˜ˆì‹œ
eval_data = [
    {"question": "Is 42 the answer to life, the universe, and everything?", "golden_answer": "Yes, according to 'The Hitchhiker's Guide to the Galaxy'."},
    {"question": "What is the capital of France?", "golden_answer": "The capital of France is Paris."}
]

def get_completion(prompt: str):
    message = client.messages.create(
        model="claude-sonnet-4-5",
        max_tokens=1024,
        messages=[
        {"role": "user", "content": prompt}
        ]
    )
    return message.content[0].text

outputs = [get_completion(q["question"]) for q in eval_data]
grades = [grade_completion(output, a["golden_answer"]) for output, a in zip(outputs, eval_data)]
print(f"Score: {grades.count('correct') / len(grades) * 100}%")
```

</details>

## ë‹¤ìŒ ë‹¨ê³„

> í‰ê°€ ì ìˆ˜ë¥¼ ê·¹ëŒ€í™”í•˜ëŠ” í”„ë¡¬í”„íŠ¸ ì‘ì„± ë°©ë²•ì„ ì•Œì•„ë³´ì„¸ìš”.


> ì‚¬ëŒ, ì½”ë“œ, LLM ê¸°ë°˜ ì±„ì  í‰ê°€ì˜ ë” ë§ì€ ì½”ë“œ ì˜ˆì‹œ.


