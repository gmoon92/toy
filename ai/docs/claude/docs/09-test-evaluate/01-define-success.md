# [성공 기준 정의하기](https://platform.claude.com/docs/en/test-and-evaluate/define-success)

---

성공적인 LLM 기반 애플리케이션을 구축하려면 명확한 성공 기준을 정의하는 것부터 시작해야 합니다. 애플리케이션을 출시해도 좋을 만큼 충분히 잘 작동한다는 것을 어떻게 알 수 있을까요?

명확한 성공 기준을 설정하면 프롬프트 엔지니어링 및 최적화 노력이 구체적이고 측정 가능한 목표를 달성하는 데 집중될 수 있습니다.

***

## 강력한 기준 구축하기

좋은 성공 기준은 다음과 같습니다:
- **구체적(Specific)**: 달성하고자 하는 것을 명확하게 정의하세요. "좋은 성능"이라고 하기보다는 "정확한 감정 분류"라고 구체적으로 명시하세요.
- **측정 가능(Measurable)**: 정량적 지표 또는 명확하게 정의된 정성적 척도를 사용하세요. 수치는 명확성과 확장성을 제공하지만, 정성적 측정도 정량적 측정과 *함께* 일관되게 적용된다면 가치가 있을 수 있습니다.
    - 윤리 및 안전과 같은 "모호한" 주제도 수치화할 수 있습니다:
        |      | 안전 기준                |
        | ---- | ------------------------------ |
        | 나쁜 예  | 안전한 출력                   |
        | 좋은 예 | 10,000번의 시도 중 콘텐츠 필터에 의해 유해성 표시를 받는 출력이 0.1% 미만이어야 함. |
    <details>
<summary>예시 지표 및 측정 방법</summary>

**정량적 지표**:
            - 작업 특화: F1 점수, BLEU 점수, perplexity
            - 일반: 정확도(Accuracy), 정밀도(Precision), 재현율(Recall)
            - 운영: 응답 시간(ms), 가동 시간(%)

        **정량적 방법**:
            - A/B 테스팅: 기준 모델 또는 이전 버전과 성능 비교
            - 사용자 피드백: 작업 완료율과 같은 암묵적 측정
            - 엣지 케이스 분석: 오류 없이 처리된 엣지 케이스의 비율

        **정성적 척도**:
            - 리커트 척도: "일관성을 1(무의미)에서 5(완벽하게 논리적)까지 평가"
            - 전문가 루브릭: 언어학자가 정의된 기준에 따라 번역 품질 평가
</details>
- **달성 가능(Achievable)**: 목표를 산업 벤치마크, 이전 실험, AI 연구 또는 전문 지식을 기반으로 설정하세요. 성공 지표는 현재 최신 모델의 기능에 비해 비현실적이어서는 안 됩니다.
- **관련성(Relevant)**: 기준을 애플리케이션의 목적 및 사용자 요구사항과 일치시키세요. 강력한 인용 정확도는 의료 앱에서는 중요할 수 있지만 일반적인 챗봇에서는 덜 중요할 수 있습니다.

<details>
<summary>감정 분석을 위한 작업 충실도 기준 예시</summary>

|      | 기준                                                     |
    | ---- | ------------------------------------------------------------ |
    | 나쁜 예  | 모델은 감정을 잘 분류해야 함                    |
    | 좋은 예 | 우리의 감정 분석 모델은 10,000개의 다양한 트위터 게시물로 구성된 홀드아웃 테스트 세트*에서 최소 0.85의 F1 점수를 달성해야 함(측정 가능, 구체적). 이는 현재 기준선보다 5% 향상된 것임(달성 가능, 관련성). |

    **다음 섹션에서 홀드아웃 테스트 세트에 대해 더 자세히 다룹니다*
</details>

***

## 고려해야 할 일반적인 성공 기준

다음은 여러분의 사용 사례에 중요할 수 있는 몇 가지 기준입니다. 이 목록이 전부는 아닙니다.

  <details>
<summary>작업 충실도(Task fidelity)</summary>

모델이 작업을 얼마나 잘 수행해야 하나요? 드물거나 까다로운 입력에 대해 모델이 얼마나 잘 수행해야 하는지와 같은 엣지 케이스 처리도 고려해야 할 수 있습니다.
</details>
  <details>
<summary>일관성(Consistency)</summary>

유사한 유형의 입력에 대해 모델의 응답이 얼마나 유사해야 하나요? 사용자가 같은 질문을 두 번 했을 때 의미적으로 유사한 답변을 받는 것이 얼마나 중요한가요?
</details>
  <details>
<summary>관련성 및 일관성(Relevance and coherence)</summary>

모델이 사용자의 질문이나 지시사항을 얼마나 직접적으로 다루나요? 정보가 논리적이고 따라가기 쉬운 방식으로 제시되는 것이 얼마나 중요한가요?
</details>
  <details>
<summary>톤과 스타일(Tone and style)</summary>

모델의 출력 스타일이 기대와 얼마나 잘 일치하나요? 대상 청중에 대한 언어가 얼마나 적절한가요?
</details>
  <details>
<summary>개인정보 보호(Privacy preservation)</summary>

모델이 개인 정보 또는 민감한 정보를 처리하는 방법에 대한 성공적인 지표는 무엇인가요? 특정 세부 정보를 사용하거나 공유하지 말라는 지시사항을 따를 수 있나요?
</details>
  <details>
<summary>컨텍스트 활용(Context utilization)</summary>

모델이 제공된 컨텍스트를 얼마나 효과적으로 사용하나요? 히스토리에 제공된 정보를 얼마나 잘 참조하고 그 위에 구축하나요?
</details>
  <details>
<summary>지연 시간(Latency)</summary>

모델의 허용 가능한 응답 시간은 얼마인가요? 이는 애플리케이션의 실시간 요구사항과 사용자 기대에 따라 달라집니다.
</details>
  <details>
<summary>가격(Price)</summary>

모델을 실행하기 위한 예산은 얼마인가요? API 호출당 비용, 모델의 크기, 사용 빈도와 같은 요소를 고려하세요.
</details>

대부분의 사용 사례는 여러 성공 기준에 따라 다차원 평가가 필요합니다.

<details>
<summary>감정 분석을 위한 다차원 기준 예시</summary>

|      | 기준                                                     |
    | ---- | ------------------------------------------------------------ |
    | 나쁜 예  | 모델은 감정을 잘 분류해야 함                    |
    | 좋은 예 | 10,000개의 다양한 트위터 게시물로 구성된 홀드아웃 테스트 세트에서 우리의 감정 분석 모델은 다음을 달성해야 함:<br/>- 최소 0.85의 F1 점수<br/>- 99.5%의 출력이 비유해성<br/>- 오류의 90%가 심각한 오류*가 아닌 불편을 초래<br/>- 95%의 응답 시간이 200ms 미만 |

    **실제로는 "불편"과 "심각한"의 의미도 정의해야 합니다.*
</details>

***

## 다음 단계


  
> claude.ai에서 Claude와 함께 사용 사례에 대한 성공 기준을 브레인스토밍하세요.<br/><br/>**팁**: 이 페이지를 채팅에 넣어 Claude를 위한 가이드로 사용하세요!

  
> 기준에 대한 Claude의 성능을 측정하기 위한 강력한 테스트 세트를 구축하는 방법을 배우세요.


